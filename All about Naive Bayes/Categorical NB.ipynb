{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author - Gowtham Ch\n",
    "# https://www.linkedin.com/in/gauthamchowta/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = ['Clear', 'Clear', 'Clear', 'Clear', 'Clear', 'Clear',\n",
    "            'Rainy', 'Rainy', 'Rainy', 'Rainy', 'Rainy', 'Rainy',\n",
    "            'Snowy', 'Snowy', 'Snowy', 'Snowy', 'Snowy', 'Snowy']\n",
    "\n",
    "timeOfWeek = ['Workday', 'Workday', 'Workday',\n",
    "            'Weekend', 'Weekend', 'Weekend',\n",
    "            'Workday', 'Workday', 'Workday',\n",
    "            'Weekend', 'Weekend', 'Weekend',\n",
    "            'Workday', 'Workday', 'Workday',\n",
    "            'Weekend', 'Weekend', 'Weekend']\n",
    "\n",
    "timeOfDay = ['Morning', 'Lunch', 'Evening',\n",
    "            'Morning', 'Lunch', 'Evening',\n",
    "            'Morning', 'Lunch', 'Evening',\n",
    "            'Morning', 'Lunch', 'Evening',\n",
    "            'Morning', 'Lunch', 'Evening',\n",
    "            'Morning', 'Lunch', 'Evening',\n",
    "            ]\n",
    "trafficJam = ['Yes', 'No', 'Yes',\n",
    "            'No', 'No', 'No',\n",
    "            'Yes', 'Yes', 'Yes',\n",
    "            'No', 'No', 'No',\n",
    "            'Yes', 'Yes', 'Yes',\n",
    "            'Yes', 'No', 'Yes'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>timeOfWeek</th>\n",
       "      <th>timeOfDay</th>\n",
       "      <th>trafficJam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clear</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clear</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clear</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clear</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Morning</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clear</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clear</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Evening</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Morning</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Evening</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Snowy</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Snowy</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Snowy</td>\n",
       "      <td>Workday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Snowy</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Snowy</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Snowy</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weather timeOfWeek timeOfDay trafficJam\n",
       "0    Clear    Workday   Morning        Yes\n",
       "1    Clear    Workday     Lunch         No\n",
       "2    Clear    Workday   Evening        Yes\n",
       "3    Clear    Weekend   Morning         No\n",
       "4    Clear    Weekend     Lunch         No\n",
       "5    Clear    Weekend   Evening         No\n",
       "6    Rainy    Workday   Morning        Yes\n",
       "7    Rainy    Workday     Lunch        Yes\n",
       "8    Rainy    Workday   Evening        Yes\n",
       "9    Rainy    Weekend   Morning         No\n",
       "10   Rainy    Weekend     Lunch         No\n",
       "11   Rainy    Weekend   Evening         No\n",
       "12   Snowy    Workday   Morning        Yes\n",
       "13   Snowy    Workday     Lunch        Yes\n",
       "14   Snowy    Workday   Evening        Yes\n",
       "15   Snowy    Weekend   Morning        Yes\n",
       "16   Snowy    Weekend     Lunch         No\n",
       "17   Snowy    Weekend   Evening        Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(zip(weather,timeOfWeek,timeOfDay,trafficJam),columns = ['weather','timeOfWeek','timeOfDay','trafficJam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = df['weather'].values.reshape(-1,1)\n",
    "timeOfWeek = df['timeOfWeek'].values.reshape(-1,1) \n",
    "timeOfDay = df['timeOfDay'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18, 1), (18, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape,timeOfWeek.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    # Using ordinal encoder to convert the categories in the range from 0 to n-1\n",
    "    wea_enc = OrdinalEncoder()\n",
    "    weather_ = wea_enc.fit_transform(weather)\n",
    "\n",
    "    timeOfWeek_enc = OrdinalEncoder()\n",
    "    timeOfWeek_ = timeOfWeek_enc.fit_transform(timeOfWeek)\n",
    "\n",
    "    timeOfDay_enc = OrdinalEncoder()\n",
    "    timeOfDay_ = timeOfDay_enc.fit_transform(timeOfDay)\n",
    "    # Stacking all the features\n",
    "    X = np.column_stack((weather_,timeOfWeek_,timeOfDay_))\n",
    "    # Changing the type to int\n",
    "    X = X.astype(int)\n",
    "    # Doing one hot encoding on the target data\n",
    "    y = df['trafficJam']\n",
    "    lb = LabelBinarizer()\n",
    "    y_ = lb.fit_transform(y)\n",
    "    if y_.shape[1] == 1:\n",
    "        y_ = np.concatenate((1 - y_, y_), axis=1)\n",
    "    return X,y_,lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18, 3), (18, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y,classes = preprocess()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_based_onclass(X,y):\n",
    "    \n",
    "    # No of feature\n",
    "    n_features = X.shape[1]\n",
    "    # No of classes\n",
    "    n_classes = y.shape[1]\n",
    "    \n",
    "    count_matrix = []\n",
    "    # For each feature\n",
    "    for i in range(n_features):\n",
    "        count_feature = []\n",
    "        # Get that particuar feature from the dataset\n",
    "        X_feature = X[:,i]\n",
    "        # For each class\n",
    "        for j in range(n_classes):\n",
    "            # Get the datapoints that belong to the class - j\n",
    "            mask = y[:,j].astype(bool)\n",
    "            # Using masking filter out the datapoints that belong to this class- j in the given feature - i\n",
    "            # Using bincount -- count all the different categories present in the given feature\n",
    "            counts = np.bincount(X_feature[mask])\n",
    "            \n",
    "            count_feature.append(counts)\n",
    "            \n",
    "        count_matrix.append(np.array(count_feature))\n",
    "        # Finding the count of datapoints beloging to each class -- we will use it to calculate prior probabilities.\n",
    "        class_count = y.sum(axis=0)\n",
    "        \n",
    "    return count_matrix,n_features,n_classes,class_count\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix,n_features,n_classes,class_count = counts_based_onclass(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4, 3, 1],\n",
       "        [2, 3, 5]], dtype=int64), array([[7, 1],\n",
       "        [2, 8]], dtype=int64), array([[2, 4, 2],\n",
       "        [4, 2, 4]], dtype=int64)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood_probs(count_matrix,alpha,n_features):\n",
    "    log_probabilities = []\n",
    "    for i in range(n_features):\n",
    "        num = count_matrix[i] + alpha\n",
    "        den = num.sum(axis = 1).reshape(-1,1)\n",
    "        log_probability = np.log(num) - np.log(den)\n",
    "        log_probabilities.append(log_probability)\n",
    "    return log_probabilities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_probs(class_count):\n",
    "    \n",
    "    num = class_count\n",
    "    den = class_count.sum()\n",
    "    \n",
    "    return np.log(num)-np.log(den)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prior_probs = calculate_prior_probs(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_probs = calculate_likelihood_probs(count_matrix,1,n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.78845736, -1.01160091, -1.70474809],\n",
       "        [-1.46633707, -1.178655  , -0.77318989]]),\n",
       " array([[-0.22314355, -1.60943791],\n",
       "        [-1.38629436, -0.28768207]]),\n",
       " array([[-1.29928298, -0.78845736, -1.29928298],\n",
       "        [-0.95551145, -1.46633707, -0.95551145]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query_point,log_probs,prior_probs):\n",
    "    \n",
    "    # Intializing an empty array\n",
    "    probs = np.zeros((1,n_classes))\n",
    "    # For each feature\n",
    "    for i in range(n_features):\n",
    "        # Get the category_id of the feature - i from the query_point\n",
    "        category = query_point[i]\n",
    "        # Fetch the corresponding log_probability table and add continue to add them for all the features\n",
    "        probs+=log_probs[i][:,category]\n",
    "    # Finally add posterior probability\n",
    "    probs+=prior_probs\n",
    "    # Finding the maximum of the probabilities and fetching the corresponding class\n",
    "    return classes[np.argmax(probs)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn feature log-probabilities\n",
      " [array([[-0.78845736, -1.01160091, -1.70474809],\n",
      "       [-1.46633707, -1.178655  , -0.77318989]]), array([[-0.22314355, -1.60943791],\n",
      "       [-1.38629436, -0.28768207]]), array([[-1.29928298, -0.78845736, -1.29928298],\n",
      "       [-0.95551145, -1.46633707, -0.95551145]])]\n",
      "Manually implemented likelihood probabilities\n",
      " [array([[-0.78845736, -1.01160091, -1.70474809],\n",
      "       [-1.46633707, -1.178655  , -0.77318989]]), array([[-0.22314355, -1.60943791],\n",
      "       [-1.38629436, -0.28768207]]), array([[-1.29928298, -0.78845736, -1.29928298],\n",
      "       [-0.95551145, -1.46633707, -0.95551145]])]\n",
      "Sklearn feature prior-probabilities\n",
      " [-0.81093022 -0.58778666]\n",
      "Manually implemented prior probabilities\n",
      " [-0.81093022 -0.58778666]\n",
      "\n",
      "Sklearn predict ['No']\n",
      "Manual predict No\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X, df['trafficJam'])\n",
    "print('Sklearn feature log-probabilities\\n',clf.feature_log_prob_)\n",
    "print('Manually implemented likelihood probabilities\\n',log_probs)\n",
    "\n",
    "print('Sklearn feature prior-probabilities\\n',clf.class_log_prior_)\n",
    "print('Manually implemented prior probabilities\\n',prior_probs)\n",
    "\n",
    "print()\n",
    "print('Sklearn predict',clf.predict(X[4:5]))\n",
    "print('Manual predict',predict(X[4],log_probs,prior_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
